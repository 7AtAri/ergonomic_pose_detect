{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Model Inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader, Subset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from ultralytics import YOLO\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model output for every layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((640, 480)), # Resize images to 640x640\n",
    "    transforms.ToTensor() # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'example_images'\n",
    "own_dataset = datasets.ImageFolder(root=data_path, transform=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(own_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "image = [i for i in train_loader][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model=YOLO(\"yolov8n-pose.pt\")\n",
    "yolo_features = nn.Sequential(*list(yolo_model.model.children())[0][:22])\n",
    "\n",
    "yolo_pose_layer = nn.Sequential(*list(yolo_model.model.children())[0][22:])\n",
    "\n",
    "yolo_pose_stem = nn.Sequential(*list(yolo_pose_layer[0].children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 0\n",
    "def print_size(module, input, output):\n",
    "    global depth\n",
    "    if isinstance(output, tuple):\n",
    "        depth += 1\n",
    "        for element in output:\n",
    "            print_size(module, input, element)\n",
    "    elif isinstance(output, list):\n",
    "        for element in output:\n",
    "            print_size(module, input, element)        \n",
    "    else:\n",
    "        #print(type(output))\n",
    "        print(f\"depth: {depth}, {module.__class__.__name__}: {output.size()}\")\n",
    "        if depth > 0:\n",
    "            depth -= 1\n",
    "\n",
    "# Assuming `yolo` is your model instance\n",
    "for layer in yolo_features.children():\n",
    "    layer.register_forward_hook(print_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetunedYOLO(nn.ModuleList):\n",
    "    def __init__(self, yolo_model, h1, h2):\n",
    "        super(FinetunedYOLO, self).__init__()\n",
    "        self.first_yolo_block = nn.Sequential(*list(yolo_model.model.modules())[0:1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            ...\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_yolo_block(x)\n",
    "        x = self.flatten_tensors(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def recursive_flatten(self, tensor_struct):\n",
    "        \"\"\"Recursively collect tensors from a nested structure.\"\"\"\n",
    "        if isinstance(tensor_struct, (list, tuple)):\n",
    "            # For list or tuple, extend by recursively processing each item\n",
    "            tensors = []\n",
    "            for item in tensor_struct:\n",
    "                tensors.extend(self.flatten_tensors(item))\n",
    "            return tensors\n",
    "        elif isinstance(tensor_struct, torch.Tensor):\n",
    "            # For tensors, return in a list\n",
    "            return [torch.flatten(tensor_struct)]\n",
    "        else:\n",
    "            # Non-tensor, non-list/tuple items are ignored\n",
    "            return []\n",
    "        \n",
    "    def flatten_tensors(self, tensor_struct):\n",
    "        return torch.flatten(torch.cat(self.recursive_flatten(tensor_struct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.1705, 18.5389, 27.3171,  ..., -3.3760, -3.2733, -3.0503])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_yolo_block = nn.Sequential(*list(yolo_model.model.modules())[0:1])\n",
    "output = first_yolo_block(image)\n",
    "\n",
    "flattened = torch.flatten(torch.cat(flatten_tensors(output)))\n",
    "flattened.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_backbone= nn.Sequential(*list(yolo_model.model.children())[0][:22]) # keeps layer 0 to 21, without the pose head (layer 22)\n",
    "pose_head= nn.Sequential(*list(yolo_model.model.children())[0][22:23])\n",
    "pose_stem= nn.Sequential(*list(pose_head[0].children())[:-1])\n",
    "#display(summary(nn.Sequential(pose_stem)))\n",
    "#summary(pose_head)\n",
    "#pose_stem=nn.Sequential(pose_head[0].cv2, pose_head[0].cv3, pose_head[0].dfl)\n",
    "yolo_pose = nn.Sequential(*yolo_backbone, pose_stem)\n",
    "display(summary(yolo_model))\n",
    "summary(yolo_pose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ergonomic_pose.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
