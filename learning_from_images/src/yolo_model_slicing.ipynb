{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Model Slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader, Subset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from ultralytics import YOLO\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune YOLOv8 pose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((640, 480)), # Resize images to 640x640\n",
    "    transforms.ToTensor() # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'example_images'\n",
    "own_dataset = datasets.ImageFolder(root=data_path, transform=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(own_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "image = [i for i in train_loader][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model=YOLO(\"yolov8n-pose.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3  \n",
    "num_features = 1083600\n",
    "h1 = 1024\n",
    "h2 = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetunedYOLO(nn.Module):\n",
    "    def __init__(self, yolo_model, input_features, num_classes, h1, h2):\n",
    "        super(FinetunedYOLO, self).__init__()\n",
    "        self.first_yolo_block = nn.Sequential(*list(yolo_model.model.modules())[0:1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            #nn.Flatten(),\n",
    "            nn.Linear(input_features, h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(h1, h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(h2, h2 // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h2 // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def recursive_flatten(self, tensor_struct):\n",
    "        \"\"\"Recursively collect tensors from a nested structure.\"\"\"\n",
    "        if isinstance(tensor_struct, (list, tuple)):\n",
    "            # For list or tuple, extend by recursively processing each item\n",
    "            tensors = []\n",
    "            for item in tensor_struct:\n",
    "                tensors.extend(self.recursive_flatten(item))\n",
    "            return tensors\n",
    "        elif isinstance(tensor_struct, torch.Tensor):\n",
    "            # For tensors, return in a list\n",
    "            return [torch.flatten(tensor_struct)]\n",
    "        else:\n",
    "            # Non-tensor, non-list/tuple items are ignored\n",
    "            return []\n",
    "        \n",
    "    def flatten_tensors(self, tensor_struct):\n",
    "        return torch.flatten(torch.cat(self.recursive_flatten(tensor_struct)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.first_yolo_block(x)\n",
    "        flattened = self.flatten_tensors(x)\n",
    "        print(flattened.shape)\n",
    "        #print(torch.nn.Flatten(flattened).shape)\n",
    "        x = self.classifier(flattened)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     x = self.first_yolo_block(x)\n",
    "    #     flattened = torch.flatten(torch.cat(self.recursive_flatten(x)))\n",
    "    #     x = self.classifier(flattened)\n",
    "        \n",
    "    #     return x\n",
    "    \n",
    "    # def recursive_flatten(self, tensor_struct):\n",
    "    #     \"\"\"Recursively collect tensors from a nested structure.\"\"\"\n",
    "    #     if isinstance(tensor_struct, (list, tuple)):\n",
    "    #         # For list or tuple, extend by recursively processing each item\n",
    "    #         tensors = []\n",
    "    #         for item in tensor_struct:\n",
    "    #             tensors.extend(self.recursive_flatten(item))\n",
    "    #         return tensors\n",
    "    #     elif isinstance(tensor_struct, torch.Tensor):\n",
    "    #         # For tensors, return in a list\n",
    "    #         return [torch.flatten(tensor_struct)]\n",
    "    #     else:\n",
    "    #         # Non-tensor, non-list/tuple items are ignored\n",
    "    #         return []\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = FinetunedYOLO(yolo_model, num_features, num_classes, h1, h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1083600])\n"
     ]
    }
   ],
   "source": [
    "out = newmodel(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.6704,  5.2526, -5.9985], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datapreparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_backbone= nn.Sequential(*list(yolo_model.model.children())[0][:22]) # keeps layer 0 to 21, without the pose head (layer 22)\n",
    "pose_head= nn.Sequential(*list(yolo_model.model.children())[0][22:23])\n",
    "pose_stem= nn.Sequential(*list(pose_head[0].children())[:-1])\n",
    "#display(summary(nn.Sequential(pose_stem)))\n",
    "#summary(pose_head)\n",
    "#pose_stem=nn.Sequential(pose_head[0].cv2, pose_head[0].cv3, pose_head[0].dfl)\n",
    "yolo_pose = nn.Sequential(*yolo_backbone, pose_stem)\n",
    "display(summary(yolo_model))\n",
    "summary(yolo_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_features = nn.Sequential(*list(yolo_model.model.children())[0][:22])\n",
    "\n",
    "yolo_pose_layer = nn.Sequential(*list(yolo_model.model.children())[0][22:])\n",
    "\n",
    "yolo_pose_stem = nn.Sequential(*list(yolo_pose_layer[0].children())[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the output size of every layer of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 0\n",
    "def print_size(module, input, output):\n",
    "    global depth\n",
    "    if isinstance(output, tuple):\n",
    "        depth += 1\n",
    "        for element in output:\n",
    "            print_size(module, input, element)\n",
    "    elif isinstance(output, list):\n",
    "        for element in output:\n",
    "            print_size(module, input, element)        \n",
    "    else:\n",
    "        #print(type(output))\n",
    "        print(f\"depth: {depth}, {module.__class__.__name__}: {output.size()}\")\n",
    "        if depth > 0:\n",
    "            depth -= 1\n",
    "\n",
    "# Assuming `yolo` is your model instance\n",
    "for layer in yolo_features.children():\n",
    "    layer.register_forward_hook(print_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example flattening of the tensors:\n",
    "(this works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tensors(tensor_struct):\n",
    "    \"\"\"Recursively collect tensors from a nested structure.\"\"\"\n",
    "    if isinstance(tensor_struct, (list, tuple)):\n",
    "        # For list or tuple, extend by recursively processing each item\n",
    "        tensors = []\n",
    "        for item in tensor_struct:\n",
    "            tensors.extend(flatten_tensors(item))\n",
    "        return tensors\n",
    "    elif isinstance(tensor_struct, torch.Tensor):\n",
    "        # For tensors, return in a list\n",
    "        return [torch.flatten(tensor_struct)]\n",
    "    else:\n",
    "        # Non-tensor, non-list/tuple items are ignored\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1083600])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_yolo_block = nn.Sequential(*list(yolo_model.model.modules())[0:1])\n",
    "output = first_yolo_block(image)\n",
    "\n",
    "flattened = torch.flatten(torch.cat(flatten_tensors(output)))\n",
    "flattened.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ergonomic_pose.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
