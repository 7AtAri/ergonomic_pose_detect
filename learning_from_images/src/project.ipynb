{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_output(image, boxes, keypoints):\n",
    "    \"\"\"\n",
    "    Visualize the output model on the input image.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The original image.\n",
    "    boxes (numpy.ndarray): Array of bounding boxes, each box is [x, y, width, height].\n",
    "    keypoints (numpy.ndarray): Array of keypoints for pose estimation.\n",
    "    \"\"\"\n",
    "\n",
    "    result_image = image.copy()\n",
    "    \n",
    "    # Font setting for the numbers\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1\n",
    "    font_thickness = 2\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    for i, box in enumerate(boxes):\n",
    "        center_x, center_y, width, height = box\n",
    "        top_left_x = int(center_x - width / 2)\n",
    "        top_left_y = int(center_y - height / 2)\n",
    "        bottom_right_x = int(top_left_x + width)\n",
    "        bottom_right_y = int(top_left_y + height)\n",
    "\n",
    "        # Draw the box\n",
    "        #cv2.rectangle(result_image, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), (0, 255, 0), 2)\n",
    "        \n",
    "        # # Write the number of the box\n",
    "        # text = str(i)\n",
    "        # (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "        # text_offset_x = top_left_x + text_width\n",
    "        # text_offset_y = top_left_y + text_height\n",
    "        # box_coords = ((text_offset_x, text_offset_y - text_height), (top_left_x, text_offset_y + 4))\n",
    "        # cv2.rectangle(result_image, box_coords[0], box_coords[1], (255, 255, 255), cv2.FILLED)\n",
    "        # cv2.putText(result_image, text, (top_left_x, text_offset_y), font, font_scale, (0, 0, 255), font_thickness)\n",
    "\n",
    "    # Draw keypoints\n",
    "    for keypoint in keypoints:\n",
    "        for x, y in keypoint:\n",
    "            cv2.circle(result_image, (int(x), int(y)), 20, (255, 0, 0), -1)\n",
    "    \n",
    "    return result_image\n",
    "\n",
    "def plot_results(image, mode=\"inline\", scale=1):\n",
    "    \"\"\"\n",
    "    Displays an image using either a popup window or inline display.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray or CV2 image\n",
    "        The image to display.\n",
    "    mode : str, optional\n",
    "        The display mode. Must be either \"popup\" or \"inline\". If \"popup\", the image is displayed in a popup window. If \"inline\", the image is displayed inline in the notebook. Default is \"inline\".\n",
    "    scale : float, optional\n",
    "        The scaling factor for the image. Default is 1.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the mode is not \"popup\" or \"inline\".\n",
    "    \"\"\"\n",
    "    \n",
    "    if mode == \"popup\":\n",
    "        pass\n",
    "    elif mode == \"inline\":\n",
    "        if type(image) == np.ndarray:\n",
    "            # Convert from BGR to RGB (because OpenCV uses BGR order for color channels, whereas PIL uses RGB.)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(image_rgb)\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be either 'popup' or 'inline'\")\n",
    "\n",
    "    if type(image) is np.ndarray:\n",
    "        cv2.imshow('Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        width, height = image.size\n",
    "        display(image.resize((int(width*scale), int(height*scale))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n-pose.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small example image prediction with visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 person, 78.1ms\n",
      "Speed: 2.9ms preprocess, 78.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "# Predict with the model\n",
    "image = cv2.imread('example_images/yellow3.jpg') \n",
    "\n",
    "results = model(image)\n",
    "\n",
    "boxes = results[0].boxes.xywh  # Boxes object for bbox outputs\n",
    "keypoints = results[0].keypoints.xy  # Keypoints object for pose outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the keypoints are also calculated in 3D which we will leverage for our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.2903e+03, 1.4783e+03, 9.9350e-01],\n",
      "         [1.3883e+03, 1.3790e+03, 9.9267e-01],\n",
      "         [1.2600e+03, 1.3812e+03, 7.7818e-01],\n",
      "         [1.7325e+03, 1.3233e+03, 9.6801e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 4.2132e-02],\n",
      "         [1.9563e+03, 1.7039e+03, 9.9153e-01],\n",
      "         [1.6893e+03, 1.5877e+03, 9.9206e-01],\n",
      "         [1.5165e+03, 2.2164e+03, 9.7732e-01],\n",
      "         [1.2452e+03, 1.8650e+03, 9.7607e-01],\n",
      "         [1.3291e+03, 2.2291e+03, 9.8469e-01],\n",
      "         [8.3613e+02, 2.0155e+03, 9.8376e-01],\n",
      "         [2.4183e+03, 2.8356e+03, 9.8898e-01],\n",
      "         [2.2288e+03, 2.7412e+03, 9.9286e-01],\n",
      "         [1.5074e+03, 2.8463e+03, 9.8288e-01],\n",
      "         [1.4614e+03, 2.7262e+03, 9.8562e-01],\n",
      "         [1.2421e+03, 3.3962e+03, 9.0765e-01],\n",
      "         [1.3356e+03, 3.2737e+03, 9.3313e-01]]])\n",
      "torch.Size([1, 17, 3])\n"
     ]
    }
   ],
   "source": [
    "#print(results)\n",
    "keypoints_all = results[0].keypoints\n",
    "#print(keypoints_3d)\n",
    "print(keypoints_all.data)\n",
    "print(keypoints_all.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = visualize_output(image, boxes, keypoints)\n",
    "# plot_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the image for the mockup:\n",
    "cv2.imwrite('ari_yellow3_kps.jpg', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tuning yolo for our classification task\n",
    "\n",
    "- option 1: freeze the complete model, use it as a feature extractor and add a classification head to be trained on our dataset\n",
    "- option 2: cut the keypoint output layer, freeze the rest of the model and add a classification head to be trained on our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) using yolo as feature extractor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freezing the yolo model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## freezing the model by setting the requires_grad attribute to False:\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining a classification layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# `feature_extractor` is the part of the model suitable for feature extraction\n",
    "\n",
    "class YOLO_kp_Classifier(nn.Module):\n",
    "    def __init__(self, num_keypoints, num_classes=3):\n",
    "        super(YOLO_kp_Classifier, self).__init__()\n",
    "        # to flatten the output \n",
    "        self.flatten = nn.Flatten()\n",
    "        # add new classification layer(s) to the model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_keypoints* 3, 512),  # 17 keypoints * 3 (x, y, z coordinates for each keypoint)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, keypoints_3d):\n",
    "        keypoints_3d = self.flatten(keypoints_3d)\n",
    "        output = self.classifier(keypoints_3d)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classifier model\n",
    "num_classes = 3  #  3-class classification problem\n",
    "num_keypoints = 17  # 17 keypoints in the model\n",
    "\n",
    "kp_classifier_model = YOLO_kp_Classifier(num_keypoints=num_keypoints, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the own dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader, Subset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resize images for the model?\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_dataset = datasets.ImageFolder(root='path/to/your/data', transform=data_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the data into train, validation and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator().manual_seed(13)  # set seed for reproducibility of the split\n",
    "train_and_val_dataset, test_dataset =random_split(own_dataset, [0.8, 0.2], generator=generator1)  # 80% training and evaluation, 20% testing\n",
    "\n",
    "#train_size = int(0.6 * len(own_dataset))\n",
    "#val_size = int(0.15 * len(own_dataset))\n",
    "#test_size = len(own_dataset) - train_size - val_size\n",
    "#train_dataset, val_dataset, test_dataset = random_split(own_dataset , [train_size, val_size, test_size], generator=generator1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataloader: (not needed anymore here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data_loaders(batch_size, train_dataset, val_dataset):\n",
    "    # Assuming `train_dataset` and `val_dataset` are already defined\n",
    "    training_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    return training_loader, validation_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature extraction with yolo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for obtaining keypoints from the YOLO model\n",
    "def get_keypoints_from_yolo(model, inputs):\n",
    "    model.eval()  # YOLO model set to evaluation mode because we are not training it\n",
    "    with torch.no_grad(): # gradients are not computed for the frozen model\n",
    "        results = model(inputs)\n",
    "        keypoints = results[0].keypoints.data  # extract the keypoints from the results\n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_keypoints_for_classifier(keypoints):\n",
    "    # processing the keypoints in a suitable format for the classifier\n",
    "    processed_data = ...  # normalization, flattening, etc.\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training the model:\n",
    "\n",
    "- with cross-entropy loss function (fits our classification task)\n",
    "- Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#%pip install scikit-learn\n",
    "#%pip install optuna\n",
    "import optuna\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classifier model\n",
    "num_classes = 3  #  3-class classification problem\n",
    "num_keypoints = 17  # 17 keypoints in the model\n",
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_model(model, optimizer, num_epochs, lr, momentum, batch_size, trial, train_loader, val_loader, device):\n",
    "    \n",
    "    kp_classifier_model = kp_classifier_model.to(device)  # move model to device\n",
    "    kp_classifier_model.train()  # set model to training mode\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs in train_loader:  # Assuming data_loader is your DataLoader instance for the dataset\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # move data to device\n",
    "            model = model.to(device) # YOLO move model to device\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "            keypoints = get_keypoints_from_yolo(model, inputs) # get keypoints from the YOLO model\n",
    "            processed_kps = process_keypoints_for_classifier(keypoints) # prepare the keypoints for the classifier\n",
    "            classification_output = kp_classifier_model(processed_kps) # get results for the classification \n",
    "            loss = criterion(classification_output , labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagate the loss\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            # todo: further processing, such as calculating accuracy or loss, goes here\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "        \n",
    "        kp_classifier_model.eval()  # model to evaluation mode\n",
    "\n",
    "        total_loss = 0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():  # no need to compute gradients, because we are in evaluation mode\n",
    "            for inputs, labels in val_loader:  # iterate over validation dataset\n",
    "                inputs, labels = inputs.to(device), labels.to(device)  # move data to device\n",
    "                keypoints = get_keypoints_from_yolo(model, inputs) # get keypoints from the YOLO model\n",
    "                processed_kps = process_keypoints_for_classifier(keypoints) # prepare the keypoints for the classifier\n",
    "                classification_output = kp_classifier_model(processed_kps) # get results for the classification \n",
    "                loss = criterion(classification_output , labels)  # compute loss\n",
    "                total_loss += loss.item()  # accumulate the loss\n",
    "                # get predictions for output\n",
    "                _, predicted = torch.max(classification_output.data, 1)\n",
    "                # collect the predictions and labels\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "            # calculate the validation metrics:\n",
    "            avg_loss = total_loss / len(val_loader)  # get the average loss\n",
    "            accuracy = (np.array(all_predictions) == np.array(all_labels)).mean()\n",
    "            f1 = f1_score(all_labels, all_predictions, average='weighted')  \n",
    "            conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "            \n",
    "            print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "            print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Validation F1 Score: {f1:.4f}\")\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(conf_matrix)\n",
    "            \n",
    "            # here: F1 score chosen as the metric to optimize\n",
    "            # other options: combining metrics like accuracy and F1 score to maximize on both\n",
    "            #                        or multi-objective optimization on F1 score and accuracy\n",
    "    return f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function was generated by gpt-4\n",
    "\n",
    "def get_k_fold_indices(n, k=5, random_seed=None):\n",
    "    \"\"\"\n",
    "    Generate indices for k-fold cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - n: Total number of samples in the dataset.\n",
    "    - k: Number of folds.\n",
    "    - random_seed: Optional seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - A list of tuples, each containing (train_indices, val_indices) for a fold.\n",
    "    \"\"\"\n",
    "    # Initialize the random generator\n",
    "    g = torch.Generator()\n",
    "    if random_seed is not None:\n",
    "        g.manual_seed(random_seed)\n",
    "    \n",
    "    # Generate a random permutation of indices\n",
    "    indices = torch.randperm(n, generator=g).tolist()\n",
    "    \n",
    "    # Calculate fold sizes\n",
    "    fold_sizes = [n // k for _ in range(k)]\n",
    "    for i in range(n % k):\n",
    "        fold_sizes[i] += 1\n",
    "    \n",
    "    # Generate train and validation indices for each fold\n",
    "    current = 0\n",
    "    folds_indices = []\n",
    "    for fold_size in fold_sizes:\n",
    "        start, end = current, current + fold_size\n",
    "        val_indices = indices[start:end]\n",
    "        train_indices = indices[:start] + indices[end:]\n",
    "        folds_indices.append((train_indices, val_indices))\n",
    "        current = end\n",
    "    \n",
    "    return folds_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-4, 5e-4, 1e-3])\n",
    "    momentum = trial.suggest_categorical(\"momentum\", [0.9, 0.95])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "    num_epochs = trial.suggest_categorical(\"num_epochs\", [100, 200, 300])\n",
    "\n",
    "    # Set up data loaders with the chosen batch size\n",
    "    # Note: You might need to modify your dataset preparation code to accommodate dynamic batch sizes\n",
    "    #train_loader, val_loader = setup_data_loaders(batch_size)\n",
    "    # Your dataset\n",
    "    # Convert dataset into a list to enable index-based access\n",
    "    dataset = list(train_and_val_dataset)\n",
    "\n",
    "    validation_scores = []\n",
    "\n",
    "    n = len(dataset)\n",
    "    folds_indices = get_k_fold_indices(n, k, random_seed=13)\n",
    "    k = 5\n",
    "    for fold, (train_idx, val_idx) in enumerate(folds_indices, start=1):\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Here, implement the training and validation for each fold\n",
    "        # This includes model initialization, training, and evaluation\n",
    "        # Initialize model and optimizer with the chosen hyperparameters\n",
    "        kp_classifier_model = YOLO_kp_Classifier(num_keypoints=num_keypoints, num_classes=num_classes)\n",
    "        optimizer = torch.optim.Adam(kp_classifier_model.classifier.parameters(), lr=lr, momentum=momentum, weight_decay=1e-5)\n",
    "    \n",
    "        # Train and evaluate the model\n",
    "        validation_score = train_and_eval_model(model, optimizer, num_epochs, lr, momentum, batch_size, trial, train_loader, val_loader, device)\n",
    "        validation_scores.append(validation_score)\n",
    "\n",
    "    return np.mean(validation_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)  # run 20 trials\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "# Re-setup data loaders, model, and optimizer using best_params...\n",
    "# Train your final model...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters ---> todo: HPO\n",
    "num_epochs = 50 # check for appropriate number of epochs\n",
    "learning_rate = 0.001  # check for appropriate learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(kp_classifier_model.classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "kp_classifier_model.train()  # set model to training mode\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs in train_loader:  # Assuming data_loader is your DataLoader instance for the dataset\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        keypoints = get_keypoints_from_yolo(model, inputs) # get keypoints from the YOLO model\n",
    "        processed_kps = process_keypoints_for_classifier(keypoints) # prepare the keypoints for the classifier\n",
    "        classification_output = kp_classifier_model(processed_kps) # get results for the classification \n",
    "        loss = criterion(classification_output , labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagate the loss\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        # todo: further processing, such as calculating accuracy or loss, goes here\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "    \n",
    "    kp_classifier_model.eval()  # model to evaluation mode\n",
    "\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # no need to compute gradients, because we are in evaluation mode\n",
    "        for inputs, labels in val_loader:  # iterate over validation dataset\n",
    "            keypoints = get_keypoints_from_yolo(model, inputs) # get keypoints from the YOLO model\n",
    "            processed_kps = process_keypoints_for_classifier(keypoints) # prepare the keypoints for the classifier\n",
    "            classification_output = kp_classifier_model(processed_kps) # get results for the classification \n",
    "            loss = criterion(classification_output , labels)  # compute loss\n",
    "            total_loss += loss.item()  # accumulate the loss\n",
    "        avg_loss = total_loss / len(val_loader)  # get the average loss\n",
    "        print(f\"Validation Loss: {avg_loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_classifier_model.eval()  # model is in evaluation mode\n",
    "\n",
    "with torch.no_grad():  # no gradient computation, because of evaluation mode\n",
    "    for inputs, labels in test_loader:  # iterate over test dataset\n",
    "        keypoints = get_keypoints_from_yolo(model, inputs)\n",
    "        prepared_data = process_keypoints_for_classifier(keypoints)\n",
    "        outputs = kp_classifier_model(prepared_data)\n",
    "\n",
    "        # todo: perform evaluation e.g., compute accuracy, confusion matrix, f1-score, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
