{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Model Inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader, Subset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model output for every layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((640, 480)), # Resize images to 640x640\n",
    "    transforms.ToTensor() # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'example_images'\n",
    "own_dataset = datasets.ImageFolder(root=data_path, transform=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(own_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "image = [i for i in train_loader][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO('yolov8n-pose.pt')\n",
    "depth = 0\n",
    "def print_size(module, input, output):\n",
    "    global depth\n",
    "    if isinstance(output, tuple):\n",
    "        depth += 1\n",
    "        for element in output:\n",
    "            print_size(module, input, element)\n",
    "    elif isinstance(output, list):\n",
    "        for element in output:\n",
    "            print_size(module, input, element)        \n",
    "    else:\n",
    "        #print(type(output))\n",
    "        print(f\"depth: {depth}, {module.__class__.__name__}: {output.size()}\")\n",
    "        if depth > 0:\n",
    "            depth -= 1\n",
    "\n",
    "# Assuming `yolo` is your model instance\n",
    "for layer in yolo_model.modules():\n",
    "    layer.register_forward_hook(print_size)\n",
    "\n",
    "yolo_model(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the summary of the YOLO model\n",
    "\n",
    "! starts the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(yolo_model, (3, 320, 320))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative:\n",
    "\n",
    "- inspect the output in front of YOLOs pose.head \n",
    "- cut the pose.head from yolo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 320\n",
    "width= 320\n",
    "\n",
    "# Assuming `model` is your YOLO model and it's already defined\n",
    "dummy_input = torch.randn(1, 3, height, width)  # Replace height and width with actual input dimensions\n",
    "\n",
    "# Initialize a temporary variable for passing data through layers\n",
    "temp_output = dummy_input\n",
    "\n",
    "# Forward pass through the model up to layer 21\n",
    "with torch.no_grad():\n",
    "    for i, module in enumerate(yolo_model.children()):  # Adjust this line based on the actual structure of your model\n",
    "        if isinstance(temp_output, tuple):\n",
    "            # If the module expects a single tensor but the current output is a tuple, \n",
    "            # you might need to adjust this part depending on how the module expects its inputs\n",
    "            temp_output = module(*temp_output)  \n",
    "        else:\n",
    "            temp_output = module(temp_output)\n",
    "        if i == 20:  # Layer indices are 0-based; layer 21 is index 20\n",
    "            break\n",
    "\n",
    "# Check if the output is a tuple and print sizes\n",
    "\n",
    "# If the final output is a tuple, select the appropriate element\n",
    "if isinstance( temp_output, tuple):\n",
    "    print(\"is tuple\")\n",
    "    for i, elem in enumerate(temp_output):\n",
    "        try:\n",
    "            output =  temp_output[i]  # Adjust this based on which part of the tuple you need\n",
    "            print(\"i: \", i, output.size())\n",
    "        except Exception as e:\n",
    "            if isinstance(elem, tuple):\n",
    "                output = elem[i]\n",
    "                print(\"i: \", i, output.size())\n",
    "            if isinstance(elem, torch.Tensor):\n",
    "                output = elem\n",
    "                print(\"i: \", i, output.size())\n",
    "            if type(elem) == list:\n",
    "                for j, e in enumerate(elem):\n",
    "                    output = elem[j]\n",
    "                    print(\"j: \", j, output.size(), i)\n",
    "            else:\n",
    "                print(e)\n",
    "else: \n",
    "    output = temp_output.size()\n",
    "    print(\"Output size of layer 21: \", output.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ergonomic_pose.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
