
by Ari Wahl

For our Ergonomic Pose App "PostureFix" we will use YOLO v8 pose as a base model. It can also run on mobile devices (Android and Os) with 6-7 frames per second\cite{https://github.com/ultralytics/ultralytics/issues/4333}, which is more than enough for our application. For data protection and privacy we will send only the keypoints from the pose detection the be evaluated online on our classification layer or alternatively run the model as a lightweight application completely on the users devices. Either way, this ensures that there is no threat for businesses or private persons as customers to be victims of spy attacs. Just having keypoints would only allow for an extremely abstract representation and is therefore a perfect measure to protect the data and privacy of our customers. For the adaption of the YOLOv8 pose model for our application, we train a classification layer on basis of the keypoint representation. To evaluate, if a pose is ergonomic or not, we collected a dataset, which uses classification levels from the well established RULA (Rapid Upper Limb Assessment) employee assessment worksheed\cite{https://www.researchgate.net/publication/362455275_Home_office_versus_ergonomic_workstation_-_is_the_ergonomic_risk_increased_when_working_at_the_dining_table_An_inertial_motion_capture_based_pilot_study}.


Modules / Packages used so far: 

ultralytics YOLO
openCV
Numpy
Pillow
Cocoa
Quartz
objc
PyObjCTools

-----------------------------------------------------
- main model:
state-of-the-art model for pose estimation from papers with code
or alternatively:
YOLO runs live within the app on the device of the user, outputs the keypoints 
and we only classify on those, meaning only the keypoints are sent to the cloud, 
which is probably a decent abstraction...
or
[mobile phone sized model for pose estimation](https://arxiv.org/pdf/2308.09084.pdf)

- fine tuning:
with own dataset according to RULA

- data privacy:
We need to ensure that the privacy of our customers is kept safe.
Therefore we propose a preprocessing of the videofeed within the app 
to so that only privacy-preserved data leaves the users device 
and ends up in the cloud where it is inserted into the machine learning model.

or federated learning approach:
run machine learning with data that remains at the source:
[PySyft](https://github.com/OpenMined/PySyft)

more federated learning approaches:
https://github.com/chaoyanghe/Awesome-Federated-Learning

Privacy-Preserving Machine Learning with Fully Homomorphic Encryption for Deep Neural Network:
https://arxiv.org/pdf/2106.07229.pdf
python implementation for homomorphic encryption: [PySeal](https://github.com/Lab41/PySEAL)

or:

* https://easyeasy.medium.com/protecting-privacy-a-comprehensive-guide-to-video-anonymization-for-ai-training-4b85fb23a61d

maybe use a GAN and do a style transfer on the user end:
(probably easier to just use the pose estimation on the mobile phone 
and send only calculated keypoints - of closest human to the cloud to do the classification?)

* https://openaccess.thecvf.com/content/CVPR2023W/ECV/papers/Jia_BlazeStyleGAN_A_Real-Time_On-Device_StyleGAN_CVPRW_2023_paper.pdf


- which XAI Method to detect which bodypart is wrongly positioned?
- Advice with arrows in the image on how to correct the posture?

- dashboard with which packages?

- eventually get TÃœV certification?
